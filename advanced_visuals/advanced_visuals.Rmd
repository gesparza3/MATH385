---
title: Exploratory Analysis of California Wildfires (1992-2015)
author: Grant Esparza
date: September 18, 2018
output: beamer_presentation
---

```{r, echo=FALSE}
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})

```

```{r, echo=FALSE, message=FALSE}

library(ggplot2)
library(RSQLite)
library(dplyr)
library(gridExtra)
library(pander)
library(scales)
library(boot)
library(ggrepel)

```

# About the Data

- Obtained from [\textcolor{blue}{Kaggle}](https://www.kaggle.com/captcalculator/wildfire-exploratory-analysis/data).

- Subset of data from Fire Program Analysis fire-occurrence database which contains 1.88 million wildfire records.
- This analysis focuses on occurences in California, which has 189,550 Wildfires over the twenty-four year period.
- Even more specifically I'll be looking at wildfires caused by arson. 

# Data Cleaning

- Data was provided in the form of an SQLite database
- Using the library  `RSQLite` I can send a query that will return a dataframe.
- From there I will group by counties in California and select occurences that were caused by arson.

# R Data Code

```{r, cache=TRUE, size="tiny"} 

## Extract fire table from database
db <-dbConnect(SQLite(), "fire_database.sqlite") 
res <- dbSendQuery(db, "SELECT * FROM Fires WHERE State == 'CA'") 
cal_fires <- dbFetch(res) 

## Get a tibble
cal_fires %>%
    filter(STAT_CAUSE_DESCR == "Arson") %>%
    group_by(FIPS_NAME) %>%
    summarise(occurences=n(), mn_size=mean(FIRE_SIZE), sum_size=sum(FIRE_SIZE)) -> num_fires
num_fires <- num_fires[1:57,]

```

# Bar Chart

```{r, echo=FALSE, message=FALSE}

ggplot(cal_fires, aes(STAT_CAUSE_DESCR, FIRE_SIZE)) + 
    geom_bar(stat="identity", fill = "red") +
    ggtitle("Total Acres Burned by Cause") + 
    xlab("Cause of Fire") + ylab("Total Acres Burned") + 
    theme_minimal() + 
    theme(axis.title.x = element_text(face = "italic"), 
          axis.title.y = element_text(face = "italic"),
          axis.text.x = element_text(angle = 50, hjust=1),
          title = element_text(face = "bold"))

```

# Boxplot

```{r, echo=FALSE, message=FALSE}

## Boxplot of fire_size caused by arson
p1 <- ggplot(num_fires, aes(1, sum_size)) +

    geom_boxplot() +
    ggtitle("Total Acres Burned 1992-2015") +
    xlab("Total Acres Burned per County") + ylab("Count") +
    scale_x_continuous(labels = scales::comma) +
    theme_minimal() + 
    theme(axis.title.x = element_text(face = "italic"), 
          axis.title.y = element_text(face = "italic"),
          title = element_text(face = "bold"))


## Histogram of fire_size caused by arson with log transformation
p2 <- ggplot(num_fires, aes(1, log(sum_size))) +
    geom_boxplot() +
    ggtitle("Total Acres Burned 1992-2015 (Log Transformation") +
    xlab("Total Acres Burned per County") + ylab("Count") +
    scale_x_continuous(labels = scales::comma) +
    theme_minimal() + 
    theme(axis.title.x = element_text(face = "italic"), 
          axis.title.y = element_text(face = "italic"),
          title = element_text(face = "bold"))

grid.arrange(p1, p2, ncol=2)

```

# Summary Statistics

```{r, size='tiny'}

pander(summarise(num_fires, Mean = mean(sum_size), Median = median(sum_size),
          Std_dev = sd(sum_size), IQR = IQR(sum_size)))

```

With the mean being much higher than the median we can come to the conclusion there are several counties with a high value for total acres burned. With a high value for our standard deviation, we can also conclude that there is a large spread in our data (or some large outliers).

# Bootstrap Mean CI

```{r, size='tiny'}

set.seed(385)
mean_sample_data <- function(data, idx) {
   mean(data[idx]) ## Mean of a vector
}

b <- boot(num_fires$sum_size, mean_sample_data, R=999) 
boot.ci(b, type="perc")

```

We are 95% confident that the true mean number of acres burned in a California county is between 1058 and 12,081 acres.

# Bootstrap Median CI

```{r, size='tiny'}

set.seed(385)
median_sample_data <- function(data, idx) {
   median(data[idx]) ## Mean of a vector
}

b <- boot(num_fires$sum_size, median_sample_data, R=999) 
boot.ci(b, type="perc")

```

We are 95% confident that the true median number of acres burned in a California county is between 178.2 and 546.4 acres.

# Bootstrap Standard Deviation CI

```{r, size='tiny'}

set.seed(385)
sd_sample_data <- function(data, idx) {
   sd(data[idx]) ## Mean of a vector
}

b <- boot(num_fires$sum_size, sd_sample_data, R=999) 
boot.ci(b, type="perc")

```

We are 95% confident that the true standard deviation of acres burned in a California county is between 3,157 and 38,179 acres.

# Scatter Plot

```{r, echo=FALSE}

## Make plot of num_fires to average fire size
ggplot(num_fires, aes(log(occurences), log(sum_size))) +
    geom_point() + 
    geom_smooth(method="lm", se=FALSE) +
    theme_minimal() + 
    theme(axis.title.x = element_text(face = "italic"), 
          axis.title.y = element_text(face = "italic"),
          title = element_text(face = "bold"))

```

# Linear Regression

```{r, echo=FALSE, fig.width=5, fig.height=5}

## Linear Regression
fire_mod <- lm(data=num_fires, log(sum_size) ~ log(occurences))

panderOptions('round', 2)
panderOptions('keep.trailing.zeros', TRUE)
pander(summary(fire_mod))

```

For every one percent increase in California wildfires in a county caused by arson, there is a 1.58% increase in total acres burned.

When the percent of fires caused by arson is zero, the amount of total acres burned will be -0.50.

# Prediction

```{r, size="tiny"}

predict(fire_mod, data.frame(occurences=c(13, 350))) ## Take the exp of the result == total acres burned`

```

If a county had 13 cases of arson the expected amount of acres burned would be `r exp(3.55)`.

If a county had 350 cases of arson the expected amount of acres burned would be `r exp(8.75)`.
Since 350 cases of arson cannot be found in the data set, this value should be considered with caution.

# Creating Map of California Counties (Code) 

```{r, size="tiny"}

## Map plot
counties <- map_data("county") %>% filter(region == "california")

## Fix county names
colnames(num_fires) <- c("subregion", "occurences", "mn_fire_size", "sum_fire_size")

## Fix subregion names
num_fires$subregion <- tolower(num_fires$subregion)

## Plot
cal_map <- ggplot(data=counties, aes(x=long, y=lat, group=group)) +
    coord_fixed(1.3) + 
    geom_polygon(color="black", fill="gray") + 
    theme_void()

```

# Creating Map of California Counties (Map)

```{r, echo=FALSE}

cal_map

```

# Wildfire Map of Total Acres Burned by Arson (Code)

```{r, size="tiny"}

## Join datasets
fire_map <- inner_join(counties, num_fires, by="subregion") 

## Plot map with data
fire_base_map <- cal_map + 
    geom_polygon(data=fire_map, aes(fill=sum_fire_size), color="black") + 
    scale_fill_gradient2(trans="log10", low="#FFFFE0", mid="#FEB24C", high="#CD0000", labels=comma) +
    ggtitle("Total Acres Burned by County 1992-2015") + 
    labs(fill="Total Acres Burned") +
    theme_void() + 
    theme(title = element_text(face="bold"))

```

# Wildfire Map of Total Acres Burned by Arson (Map)

```{r, echo=FALSE}

fire_base_map

```

# Wildfire Map With Biggest Fire per Year (Code)

```{r, size='tiny'}

## Create tibble of biggest fire per year
cal_fires %>% 
    group_by(FIRE_YEAR) %>%
    summarise(max=which.max(FIRE_SIZE), 
             subregion=cal_fires[which.max(FIRE_SIZE),]$FIPS_NAME,
             long=cal_fires[which.max(FIRE_SIZE),]$LONGITUDE, 
             lat=cal_fires[which.max(FIRE_SIZE),]$LATITUDE) -> biggest_fire


## Plot with points
map_with_points <- fire_base_map + 
    geom_point(data=biggest_fire, aes(x=long, y=lat), inherit.aes=FALSE, size=3) +
	geom_label_repel(data=biggest_fire, aes(x=long, y=lat, label = FIRE_YEAR), 
		box.padding   = 0.35, 
        point.padding = 0.5,
        segment.color = 'grey50', inherit.aes=FALSE)

```

# Wildfire Map With Biggest Fire per Year (Map)

```{r, echo=FALSE}

map_with_points

```

